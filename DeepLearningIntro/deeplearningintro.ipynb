{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume 3: Intro to Deep Learning\n",
    "    <Name>\n",
    "    <Class>\n",
    "    <Date>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTEKNr9cHvBg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "#assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_83nhfH4GXe"
   },
   "source": [
    "# Problem 1\n",
    "Create the device variable.\n",
    "Download the CIFAR10 training and test datasets.\n",
    "Transform them into tensors and normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "md5EnYI2Rt3w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_n_LX7YU_eF7"
   },
   "source": [
    "# Problem 2\n",
    "Split the data into train, validation, and test sets, and create DataLoaders for each one. Use a batch size of 32 for the training set and 1 for the validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7pX2Cc8Hw0V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtH3WXXf_ifL"
   },
   "source": [
    "# Problem 3\n",
    "\n",
    "Create a class for a convolutional neural network that accepts images as $3\\times 32 \\times 32$ tensors and returns a 1D tensor of length 10, representing its predicted probabilities of each class.\n",
    "\n",
    "The model should have at least three convolution layers, each followed by an activation function, a max pooling layer, and at least two linear layers.\n",
    "Choose the size of the layers so that your model has at least 50,000 parameters, and record this calculation in the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDzx4o866HuF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "Send your model to the device and instantiate the objective and optimizer.\n",
    "Train your model with a TQDM display, and calculate the Validation Accuracy after each epoch. \n",
    "Begin by initializing your TQDM loop, then for each epoch, do the following:\n",
    "\n",
    "1. Set your model to training mode (model.train())\n",
    "2. Instantiate an empty loss_list\n",
    "3. For each batch in train_loader:\n",
    "    - Send x and y_truth to device\n",
    "    - Zero out the gradients \n",
    "    - Use model to predict labels of x\n",
    "    - Calculate loss between predicted labels and y_truth\n",
    "    - Append loss (loss.item()) to loss_list\n",
    "    - Update TQDM loop \n",
    "    - Backpropagate to compute gradients \n",
    "    - Optimize and update the weights\n",
    "4. Save the loss mean as the mean of the losses in loss_list\n",
    "5. Set your model to evaluation mode (model.eval())\n",
    "6. Calculate and save validation accuracy\n",
    "Finish the training by closing your TQDM loop.\n",
    "\n",
    "Train for 10 epochs, saving the mean loss and validation accuracy for each epoch.\n",
    "Plot the mean losses and validation accuracies.\n",
    "\n",
    "Finally, print the final test score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEvqbSSe_xe8"
   },
   "source": [
    "# Problem 5\n",
    "\n",
    "Write a function that loops through the test data, modifying the images as described.\n",
    "\n",
    "Run your function for each epsilon in $[0,.05,.1,.15,.2,.25,.3]$, and plot epsilon v. accuracy.\n",
    "\n",
    "Display the perturbed version of the first image in the test data for each epsilon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4oECv5Xad3k"
   },
   "outputs": [],
   "source": [
    "# FGSM attack code\n",
    "def fgsm_attack(model, optimizer, objective, x, y, eps):\n",
    "    \"\"\"\n",
    "    Performs the FGSM attack on the given model and data point x with label y.\n",
    "    Returns the perturbed data point.\n",
    "    \"\"\"\n",
    "    # Calculate the gradient\n",
    "    x.requires_grad = True\n",
    "    x.retain_grad()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    loss = objective(output, y)\n",
    "    loss.backward()\n",
    "    data_grad = x.grad.data\n",
    "    # Perturb the images\n",
    "    x_perturbed = x + eps * data_grad.sign()\n",
    "    return x_perturbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMsLmlpSnGqq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
