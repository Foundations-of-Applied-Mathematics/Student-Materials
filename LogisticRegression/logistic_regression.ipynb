{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume 3: Logistic Regression\n",
    "    <Name>\n",
    "    <Class>\n",
    "    <Date>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Create a classifier called `LogiReg` that accepts an $(n \\times 1)$ array $y$ of binary labels ($0$'s and $1$'s) as well as an $(n \\times d)$ array $X$ of data points. Write a `fit()` method that finds and saves the optimal $\\widehat{\\boldsymbol{\\beta}}$.\n",
    "\n",
    "## Problem 2\n",
    "\n",
    "Write a method called `predict_prob()` that accepts an $(n \\times d)$ array $x\\_test$ and returns $P(Y=1 | x\\_test)$. Also write a method called `predict()` that calls `predict_prob()` and returns an array of predicted labels ($0$'s or $1$'s) for the given array $x\\_test$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogiReg(): \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        input:\n",
    "        X: ndarray(n, d)\n",
    "        y: ndarray(n, 1) taking values only in {0,1}\n",
    "        \n",
    "        Save y and X as attributes.\n",
    "        Updates beta, the coefficient array of shape (d, 1) that\n",
    "        minimizes the negative log likelihood for the given data \n",
    "        with the model p(y|x) = sigm(x^T @ beta).      \n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Problem 1 Incomplete\")\n",
    "\n",
    "        \n",
    "    def predict_prob(self, x_test):\n",
    "        \"\"\"\n",
    "        Returns the predicted probability of an input x_test.\n",
    "        If x_test has shape (p, q), then the predicted probability\n",
    "        has shape (1, q).\n",
    "        \"\"\" \n",
    "        raise NotImplementedError(\"Problem 2 Incomplete\")\n",
    "        \n",
    "        \n",
    "    def predict(self, x_test):\n",
    "        \"\"\"\n",
    "        Returns the predicted classification (1 or 0) of x_test.\n",
    "        If x_test has shape (p, q), then the predicted classification\n",
    "        has shape (1, q).\n",
    "        \"\"\"      \n",
    "        raise NotImplementedError(\"Problem 2 Incomplete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Test your classifier from the previous two problems using arrays $X$, $y$, and $X\\_test$. Train your classifier on $X$ and $y$. Then generate a list of predicted labels using your trained classifier and $X\\_test$, and use it to plot $X\\_test$ with a different color for each predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.column_stack(( \n",
    "    np.concatenate(( \n",
    "        # draw from 2 2-dim. multivariate normal dists.\n",
    "        np.random.multivariate_normal(np.array([1,2]), np.eye(2), 100),\n",
    "        np.random.multivariate_normal(np.array([4,3]), np.eye(2), 100) )), \n",
    "    # labels corresonding to each distribution\n",
    "    np.concatenate(( np.zeros(100), np.ones(100) )) ))\n",
    "np.random.shuffle(data)\n",
    "# extract X and y from the shuffled data\n",
    "X = data[:,:2]\n",
    "y = data[:,2].astype(int)\n",
    "\n",
    "X_test = np.concatenate(( \n",
    "    # draw from 2 identical 2-dim. multivariate normal dists.\n",
    "    np.random.multivariate_normal(np.array([1,2]), np.eye(2), 100),\n",
    "    np.random.multivariate_normal(np.array([4,3]), np.eye(2), 100) ))\n",
    "np.random.shuffle(X_test)\n",
    "\n",
    "\n",
    "raise NotImplementedError(\"Problem 3 Incomplete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "Using each of `LogiReg`, `statsmodels.Logit`, `sklearn.LogisticRegression`, and `sklearn.svm` train a logistic regression classifier on $X$ and $y$ to generate a list of predicted labels for $X\\_test$. Then, using $y\\_test$, print the accuracy scores for each trained model. Compare the accuracies and training/testing time for all three classifiers. Be sure to add a constant feature with each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predefine the true beta\n",
    "beta = np.random.normal(0, 7, 20)\n",
    "\n",
    "# X is generated from 2 20-dim. multivariate normal dists.\n",
    "X = np.concatenate(( \n",
    "        np.random.multivariate_normal(np.zeros(20), np.eye(20), 100), \n",
    "        np.random.multivariate_normal(np.ones(20)*2, np.eye(20), 100) ))\n",
    "np.random.shuffle(X)\n",
    "# create y based on the true beta\n",
    "pred = 1. / (1. + np.exp(-X @ beta))  \n",
    "y = np.array( [1 if pred[i] >= 1/2 else 0 \n",
    "            for i in range(pred.shape[0])] )\n",
    "\n",
    "# X_test and y_test are generated similar to X and y\n",
    "X_test = np.concatenate(( \n",
    "        np.random.multivariate_normal(np.zeros(20), np.eye(20), 100), \n",
    "        np.random.multivariate_normal(np.ones(20), np.eye(20), 100) ))\n",
    "np.random.shuffle(X_test)\n",
    "pred = 1. / (1. + np.exp(-X_test @ beta))\n",
    "y_test = np.array( [1 if pred[i] >= 1/2 else 0 \n",
    "            for i in range(pred.shape[0])] )\n",
    "\n",
    "\n",
    "raise NotImplementedError(\"Problem 4 Incomplete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "Import the Iris Dataset and perform a train-test split on only the first two columns of the data with `test_size=0.4`. Train a multinomial logistic regression model using the training data with an added constant feature, and generate prediction labels for the test data.\n",
    "\n",
    "Plot the test data by color using your prediction labels. Also, print the model score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"Problem 5 Incomplete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
