{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_HaCF0y2YpwU"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade music21\n",
    "from music21 import converter, instrument, note, chord, stream, midi\n",
    "from google.colab import files\n",
    "import glob\n",
    "import os\n",
    "import gzip\n",
    "import tarfile    \n",
    "from torchvision import datasets                  \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQLLgkzrYviL"
   },
   "outputs": [],
   "source": [
    "# Import Drive for easier saving\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rCbORzBiYy6f"
   },
   "outputs": [],
   "source": [
    "def download_data(filepath):\n",
    "    if not os.path.exists(os.path.join(filepath, 'mozart_sonatas.tar.gz')):\n",
    "        datasets.utils.download_url('https://github.com/Foundations-of-Applied-Mathematics/Data/raw/master/RNN/mozart_sonatas.tar.gz', filepath, 'mozart_sonatas.tar.gz', None)\n",
    "\n",
    "    print('Extracting {}'.format('mozart_sonatas.tar.gz'))\n",
    "    gzip_path = os.path.join(filepath, 'mozart_sonatas.tar.gz')\n",
    "    with open(gzip_path.replace('.gz', ''), 'wb') as out_f, gzip.GzipFile(gzip_path) as zip_f:\n",
    "        out_f.write(zip_f.read())\n",
    "\n",
    "    print('Untarring {}'.format('mozart_sonatas.tar'))\n",
    "    tar_path = os.path.join(filepath,'mozart_sonatas.tar')\n",
    "    z = tarfile.TarFile(tar_path)\n",
    "    z.extractall(tar_path.replace('.tar', ''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m7WTL6LYY0uP"
   },
   "source": [
    "# Problem 1 #\n",
    "\n",
    "Download the data.\n",
    "Write a function that accepts the path to the .mid files, parses the files, and returns a list of the 114215 Notes and Chords as strings. \n",
    "There are many element types in MIDI files, so be sure to only look for Notes and Chords.\n",
    "For the Chords, join the pitches of the Notes in the Chords with a . as in (D3.D2).\n",
    "\n",
    "Print the length of your list and the number of unique Notes and Chords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEpK4GIyZCWg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3votXpqiZCtY"
   },
   "source": [
    "# Problem 2 #\n",
    "\n",
    "Using the list returned in Problem 1, create the training, validation, and testing DataLoaders.\n",
    "Make sure to do all of the following steps:\n",
    "\n",
    "\n",
    "1) Convert the pitches to integers.\n",
    "\n",
    "2) Split the data into Long tensors of length 100.\n",
    "\n",
    "3) Create the labels.\n",
    "\n",
    "4) Randomly split the data into training, validation, and test sets using an 70/15/15 split (use torch.utils.data.random(data,lengths) where lengths=[0.7, 0.15, 0.15]).\n",
    "\n",
    "5) Create the DataLoaders for these sets of data, using batch_size=128 for the training data and batch_size=32 for the validation and test data; also, set shuffle=True for the training data and False for the validation and test data (this is common practice in Deep Learning).\n",
    " \n",
    "\n",
    "Print the length of each DataLoader (they should be 624, 536, and 536, respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UghZuJfxZuzO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOtS86Rbi0P_"
   },
   "source": [
    "# Problem 3 #\n",
    "\n",
    "Create an LSTM network class.\n",
    "Have a hidden layer size of 256, and include at least $3$ LSTM layers.\n",
    "Also have at least $2$ Linear layers.\n",
    "The last LSTM layer and each of the Linear layers should be followed by a BatchNorm1d layer, for a total of at least $3$ total BatchNorm layers.\n",
    "The final layer should be a Softmax activation.\n",
    "\n",
    "Initialize the model.\n",
    "Define the loss as CrossEntropyLoss, and define the optimizer as RMSprop.\n",
    "\n",
    "Train the model for 30 epochs.\n",
    "Make sure to reinitialize the hidden states (h0, h1) for each training batch.\n",
    "After taking a backwards step during training, scale the gradients using\n",
    "nn.utils.clip_grad_norm_(model.parameters(), 5).\n",
    "This will ensure that the gradients are reasonably sized so that the model can learn.\n",
    "\n",
    "At the end of every epoch, calculate the validation accuracy and mean loss on the validation data.\n",
    "Remember to change the model to eval() mode when running the validation data and then train() when running on the training data.\n",
    "The hidden states (h0, h1) will also need to be reinitialized for each validation batch.\n",
    "\n",
    "Once the training is complete, plot the training and validation losses versus epochs on the same plot.\n",
    "Also, plot the validation accuracy versus epochs.\n",
    "Then, print the final test accuracy by running the finished model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMhH1W7ciwzB"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \"\"\" Recurrent Neural Network Class \"\"\"\n",
    "\n",
    "    def __init__(self, n_notes, embedding_dim):\n",
    "        super(RNN, self).__init__()\n",
    "    \n",
    "        # initialize layers\n",
    "      \n",
    "    def forward(self, x, hidden):\n",
    "        pass\n",
    "        # forward pass\n",
    "\n",
    "    def init_hidden(self,batch_size):\n",
    "        # initialize the hidden layers\n",
    "        weight = next(self.parameters()).data\n",
    "        h0 = weight.new(self.num_layers, batch_size, self.hidden_size).zero_().to(device)\n",
    "        h1 = weight.new(self.num_layers, batch_size, self.hidden_size).zero_().to(device)\n",
    "        return (h0, h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZilPcMCmOED"
   },
   "source": [
    "# Problem 4 #\n",
    "\n",
    "Write a function that randomly chooses a sequence in the test data (which has length 10) and predicts the next $n$ elements, defaulting to 500.\n",
    "Convert the predicted elements to pitches, and return them as a list of length $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HciNV-gnLOA"
   },
   "outputs": [],
   "source": [
    "def load_model(filename):\n",
    "    \"\"\" Load a saved model to continue training or evaluate \"\"\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # n_notes is the number of unique pitches\n",
    "    model = Network(n_notes,32)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(),lr=.001)\n",
    "\n",
    "    checkpoint = torch.load(filename,map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    model.eval() # Toggle evaluation mode\n",
    "\n",
    "    return model, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-syHIeZ4nLhh"
   },
   "source": [
    "# Problem 5 # \n",
    "\n",
    "Convert the predictions from Problem 4 into Music21 Note and Chord objects and save it as 'mozart.mid'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
